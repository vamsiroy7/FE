import pandas as pd
import numpy as np
import warnings

def impute_missing_values(data, columns, impute_value=0, random_state=0):
    """
    Handles missing values in specified columns using various imputation strategies,
    and ensures no columns are left with null values post-imputation. Removes any 
    columns still containing nulls after attempted imputation. Reports on the state
    of columns with null values before and after imputation.

    Parameters:
    - data (DataFrame): The input dataframe.
    - columns (list): Columns to process for NA values.
    - impute_value (int, float): The arbitrary value to impute missing values, default is 0.
    - random_state (int): Seed for the random number generator, used in random sampling.

    Returns:
    - DataFrame: The dataframe with imputed values, columns free of nulls,
                 and additional columns indicating imputation.
    - DataFrame: Columns with nulls before imputation and their count.
    """
    data_copy = data.copy(deep=True)
    
    # Detect and report columns with null values before imputation
    null_columns_before = data_copy[columns].isnull().sum()
    null_columns_before = null_columns_before[null_columns_before > 0]
    if not null_columns_before.empty:
        print("Columns with null values before imputation:")
        print(null_columns_before)
        print("Total number of columns with nulls before imputation:", null_columns_before.shape[0])
    else:
        print("No columns with null values detected before imputation.")

    # Handling NA values in specified columns
    for col in columns:
        if data_copy[col].isnull().sum() > 0:
            # Mark columns with missing values
            data_copy[col + '_is_NA'] = np.where(data_copy[col].isnull(), 1, 0)

            # Impute with a constant value
            data_copy[col + '_impute_' + str(impute_value)] = data_copy[col].fillna(impute_value)

            # Statistical imputation
            mean_val = data_copy[col].mean()
            median_val = data_copy[col].median()
            mode_val = data_copy[col].mode()[0] if not data_copy[col].mode().empty else np.nan
            eod_val = mean_val + 3 * data_copy[col].std()

            data_copy[col + '_impute_mean'] = data_copy[col].fillna(mean_val)
            data_copy[col + '_impute_median'] = data_copy[col].fillna(median_val)
            data_copy[col + '_impute_mode'] = data_copy[col].fillna(mode_val)
            data_copy[col + '_impute_end_of_distri'] = data_copy[col].fillna(eod_val)

            # Random sampling imputation
            random_sample = data_copy[col].dropna().sample(data_copy[col].isnull().sum(), random_state=random_state)
            random_sample.index = data_copy[data_copy[col].isnull()].index
            data_copy[col + '_impute_random'] = data_copy[col].fillna(random_sample)

    # Detect and report columns with null values after imputation
    null_columns_after = data_copy.isnull().sum()
    null_columns_after = null_columns_after[null_columns_after > 0]
    if not null_columns_after.empty:
        print("Columns with null values after imputation:")
        print(null_columns_after)
    else:
        print("No columns with null values remaining after imputation.")

    # Remove columns that still have null values
    if not null_columns_after.empty:
        data_copy.drop(columns=null_columns_after.index, inplace=True)

    return data_copy, null_columns_before
