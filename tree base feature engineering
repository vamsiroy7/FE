from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
import pandas as pd

def tree_based_feature_engineering(data, y, random_state=42):
    data_copy = data.copy(deep=True)

    # Fill NA values with 0 for training
    X_train_filled = data_copy.fillna(0)
    
    # Gradient Boosting Classifier
    gbdt = GradientBoostingClassifier(n_estimators=20, random_state=random_state)
    gbdt.fit(X_train_filled, y)
    gbdt_leaf_index = gbdt.apply(X_train_filled)[:, :, 0]
    
    one_hot_gbdt = OneHotEncoder()
    one_hot_gbdt.fit(gbdt_leaf_index)
    X_gbdt_one_hot = one_hot_gbdt.transform(gbdt_leaf_index).toarray()
    
    # Random Forest Classifier
    rf = RandomForestClassifier(n_estimators=20, random_state=random_state)
    rf.fit(X_train_filled, y)
    rf_leaf_index = rf.apply(X_train_filled)
    
    one_hot_rf = OneHotEncoder()
    one_hot_rf.fit(rf_leaf_index)
    X_rf_one_hot = one_hot_rf.transform(rf_leaf_index).toarray()
    
    # Concatenate the new features with the original dataframe
    data_copy = pd.concat([
        data_copy.reset_index(drop=True),
        pd.DataFrame(X_gbdt_one_hot, columns=[f'gbdt_{i}' for i in range(X_gbdt_one_hot.shape[1])]),
        pd.DataFrame(X_rf_one_hot, columns=[f'rf_{i}' for i in range(X_rf_one_hot.shape[1])])
    ], axis=1)
    
    return data_copy



import pandas as pd
import numpy as np

# Hypothetical banking data
data = pd.DataFrame({
    'age': [25, 45, 35, 50, 23, 37, 60, 41, 29, 33],
    'balance': [1000, 2500, 1500, 3000, 1200, 2000, 5000, 2200, 1800, 1600],
    'duration': [100, 200, 150, 300, 120, 180, 400, 250, 160, 140],
    'campaign': [1, 2, 1, 3, 2, 1, 4, 3, 2, 1]
})

# Target variable
y = pd.Series([0, 1, 0, 1, 0, 0, 1, 1, 0, 0])

# Applying tree-based feature engineering
processed_data = tree_based_feature_engineering(data, y, random_state=42)

print(processed_data)
